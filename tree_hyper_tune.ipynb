{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "near_jako_11 = pd.read_csv('jakobshavn11.csv')\n",
    "near_jako_12 = pd.read_csv('jakobshavn12.csv')\n",
    "near_jako_13 = pd.read_csv('jakobshavn13.csv')\n",
    "near_jako_14 = pd.read_csv('jakobshavn14.csv')\n",
    "near_jako_15 = pd.read_csv('jakobshavn15.csv')\n",
    "near_jako_16 = pd.read_csv('jakobshavn16.csv')\n",
    "near_south_11 = pd.read_csv('southeast11.csv')\n",
    "near_south_12 = pd.read_csv('southeast12.csv')\n",
    "near_south_13 = pd.read_csv('southeast13.csv')\n",
    "near_south_14 = pd.read_csv('southeast14.csv')\n",
    "near_south_15 = pd.read_csv('southeast15.csv')\n",
    "near_south_16 = pd.read_csv('southeast16.csv')\n",
    "near_stor_11 = pd.read_csv('storstrommen11.csv')\n",
    "near_stor_12 = pd.read_csv('storstrommen12.csv')\n",
    "near_stor_13 = pd.read_csv('storstrommen13.csv')\n",
    "near_stor_14 = pd.read_csv('storstrommen14.csv')\n",
    "near_stor_15 = pd.read_csv('storstrommen15.csv')\n",
    "near_stor_16 = pd.read_csv('storstrommen16.csv')\n",
    "\n",
    "near_jako = pd.concat([near_jako_11, near_jako_12, near_jako_13, \n",
    "                      near_jako_14, near_jako_15, near_jako_16])\n",
    "near_south = pd.concat([near_south_11, near_south_12, near_south_13, \n",
    "                       near_south_14, near_south_15, near_south_16])\n",
    "near_stor = pd.concat([near_stor_11, near_stor_12, near_stor_13, \n",
    "                      near_stor_14, near_stor_15, near_stor_16])\n",
    "\n",
    "near_df = pd.concat([near_jako, near_south, near_stor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "near_df_cle = near_df[(near_df['DemDiff_Swath']>-50)&\n",
    "                      (near_df['DemDiff_Swath']<25)&\n",
    "                      (near_df['MeanDiffSpread_Swath']<200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = near_df_cle[['Coh_Swath', \n",
    "                       'Coh_SwathOverPoca', \n",
    "                       'DayInYear_Swath',\n",
    "                       'Dist_SwathToPoca', \n",
    "                       'Heading_Swath',\n",
    "                       'LeadEdgeS_Poca', \n",
    "                       'LeadEdgeW_Poca',\n",
    "                       'PhaseConfidence_Swath', \n",
    "                       'PhaseSSegment_Swath',\n",
    "                       'Phase_Swath', \n",
    "                       'Phase_SwathOverPoca', \n",
    "                       'PowerScaled_Swath',\n",
    "                       'PowerScaled_SwathOverPoca', \n",
    "                       'PowerWatt_Swath', \n",
    "                       'SampleNb_Swath',\n",
    "                       'SampleNb_SwathMinusLeadEdgeS']]\n",
    "\n",
    "target = near_df_cle['Elev_Oib'] - near_df_cle['Elev_Swath']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stand_trans = MinMaxScaler().fit_transform(np.array(feature))\n",
    "target_trans = np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_stand = pd.DataFrame(stand_trans)\n",
    "feature_stand.columns = feature.columns\n",
    "feature_stand['target'] = target_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = feature_stand.sample(frac = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_small = np.array(df_small[feature.columns])\n",
    "y_small = np.array(df_small['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_estor = ExtraTreesRegressor()\n",
    "tree_para = {'n_estimators':[100, 200], \n",
    "            'max_features':[4, 16], \n",
    "            'min_samples_split': [2, 5]}\n",
    "para_search = GridSearchCV(tree_estor, tree_para, cv = 10)\n",
    "para_search_fit = para_search.fit(X_small, y_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 16, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print(para_search_fit.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
